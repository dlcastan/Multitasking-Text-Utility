# Proyecto Integrador I de Henry

Carrera: AI Engineering  
Alumno: Diego Lopez Castan

Este repositorio contiene los tres primeros proyectos de la carrera de Data Engineer de Henry. 

# ğŸ§  Multitasking Text Utility â€“ OpenAI API

## ğŸ“Œ Contexto

Este proyecto implementa una aplicaciÃ³n mÃ­nima orientada a producto que funciona como **asistente para agentes de soporte al cliente**.  
El sistema recibe una pregunta del usuario y devuelve una **respuesta estructurada en JSON**, diseÃ±ada para ser consumida por sistemas downstream (dashboards, CRM, workflows automÃ¡ticos, etc.).

AdemÃ¡s de la respuesta, el sistema **registra mÃ©tricas clave por consulta** (tokens, latencia y costo estimado), permitiendo monitorear uso, performance y costos operativos.

---

## ğŸ¯ Objetivos del Proyecto

El objetivo principal es construir un **contrato estable de salida** y demostrar buenas prÃ¡cticas en el desarrollo de aplicaciones con LLMs.

### QuÃ© se entrega y por quÃ© importa

- **Endpoint o script ejecutable** que:
  - Recibe una pregunta del usuario.
  - Devuelve **JSON vÃ¡lido** con campos bien definidos:
    - `answer`
    - `confidence`
    - `actions`
    - `metrics`
- **Registro de mÃ©tricas por ejecuciÃ³n**:
  - `prompt_tokens`
  - `completion_tokens`
  - `total_tokens`
  - `latency_ms`
  - `estimated_cost_usd`
- **AplicaciÃ³n explÃ­cita de una tÃ©cnica de prompt engineering**, documentada y justificada.
- **Reporte tÃ©cnico breve (1â€“2 pÃ¡ginas)** describiendo:
  - Arquitectura
  - TÃ©cnica de prompting
  - Ejemplos de mÃ©tricas
  - Trade-offs
- **Al menos un test automatizado** (validaciÃ³n de JSON, mÃ©tricas o tokens).
- **(Opcional)** Manejo de prompts adversariales / fallback de seguridad.

---

## ğŸ§© Arquitectura General

```
User Question
   â†“
Prompt Builder (Prompt Engineering)
   â†“
OpenAI API
   â†“
Structured JSON Response
   â†“
Metrics Logger
```

---

## ğŸ§ª TÃ©cnica de Prompt Engineering

### TÃ©cnica elegida: **Few-Shot Prompting**

Se utiliza **few-shot prompting** para mostrarle explÃ­citamente al modelo ejemplos de entrada y salida esperadas en formato JSON.

**Â¿Por quÃ© esta tÃ©cnica?**

- Reduce variabilidad en la estructura del output.
- Mejora la consistencia del formato JSON.
- Facilita integraciones downstream.
- Es simple, efectiva y fÃ¡cil de mantener en equipos pequeÃ±os.

---

## ğŸ“¦ Formato de Respuesta (Contrato JSON)

```json
{
  "answer": "Puedes restablecer tu contraseÃ±a desde la pÃ¡gina de inicio de sesiÃ³n.",
  "confidence": 0.87,
  "actions": [
    "Enviar enlace de recuperaciÃ³n",
    "Escalar a soporte humano si falla"
  ],
  "metrics": {
    "prompt_tokens": 120,
    "completion_tokens": 80,
    "total_tokens": 200,
    "latency_ms": 950,
    "estimated_cost_usd": 0.0024
  }
}
```

---

## ğŸ“Š MÃ©tricas Registradas

- Prompt tokens  
- Completion tokens  
- Total tokens  
- Latencia en milisegundos  
- Costo estimado en USD  

---

## ğŸ§ª Testing

Incluye tests automatizados para validar:

- JSON vÃ¡lido
- Presencia de campos obligatorios
- MÃ©tricas numÃ©ricas consistentes

---

## ğŸ›¡ï¸ Seguridad (Bonus)

Manejo opcional de prompts adversariales (prompt injection, requests fuera de dominio), manteniendo siempre el contrato JSON.

---

## ğŸš€ EjecuciÃ³n

### Requisitos
- Python 3.9+
- OpenAI API Key

### InstalaciÃ³n
```bash
pip install -r requirements.txt
```

### EjecuciÃ³n
```bash
python main.py
```

---

## ğŸ“„ Reporte TÃ©cnico

El proyecto incluye un reporte breve (1â€“2 pÃ¡ginas) con arquitectura, prompting, mÃ©tricas y trade-offs.

---

## ğŸ“Œ ConclusiÃ³n

Este proyecto demuestra buenas prÃ¡cticas para construir sistemas de IA confiables, observables y escalables, sirviendo como base para futuras extensiones como RAG o agentes inteligentes.
